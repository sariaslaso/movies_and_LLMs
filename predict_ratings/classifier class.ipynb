{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbf794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4207818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('model/fine_tuned_BERT')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")\n",
    "\n",
    "model_path = 'model/fine_tuned_BERT'\n",
    "tokenizer_path = 'tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36ca0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def preProcessInput(titles, summaries, genres):\n",
    "# titles: list of strings in the form: [title_1, title_2, ...]\n",
    "# summaries: list of summaries(strings) in the form: [summary_1, summary_2, ...]\n",
    "# genres: list of genres in the form: [[genres_1], [genres_2], ...] with genres_i = \"genres_i1\", \"genres_i2\", ...\n",
    "    \n",
    "    inputs = []\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        # normalice spacing in the titles\n",
    "        title_i = (' ').join(titles[i].split())\n",
    "        \n",
    "        # normalice spacing in the summaries\n",
    "        summary_i = (' ').join(summaries[i].split())\n",
    "        \n",
    "        if genres[i] == []:\n",
    "            genres_i = 'NonGiven'\n",
    "        else:\n",
    "            # convert the lists of genres to strings separated by '|'\n",
    "            genres_i = '|'.join(genres[i])\n",
    "            \n",
    "        input_i = {'title': title_i, 'summary': summary_i, 'genres': genres_i}\n",
    "        inputs.append(input_i)\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "\n",
    "def tokenizeInputs(inputs):\n",
    "    title_mod = [movie['title'] + '<SEP>' + movie['summary'] for movie in inputs]\n",
    "    genres_list = [movie['genres'] for movie in inputs]\n",
    "    \n",
    "        \n",
    "    return tokenizer(title_mod, genres_list, padding = 'max_length', truncation = True, \n",
    "                     return_tensors = \"pt\")\n",
    "\n",
    "\n",
    "def modelPredictions(model, tokenized_input):\n",
    "# generate model predictions using the model logits and tokenized input and determine \n",
    "# the most likely rating using\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(**tokenized_input)\n",
    "        \n",
    "    logits = model_output.logits\n",
    "    predictions = np.argmax(logits, axis = -1)\n",
    "    \n",
    "    return predictions           \n",
    "            \n",
    "def modelMovieRating(predictions):\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        if pred == 0:\n",
    "            predicted_ratings.append((pred, \"bad\"))\n",
    "        elif pred == 1:\n",
    "            predicted_ratings.append((pred, \"average\"))\n",
    "        else:\n",
    "            predicted_ratings.append((pred, \"good\"))\n",
    "            \n",
    "    return predicted_ratings\n",
    "            \n",
    "class MovieClassifier:\n",
    "#     this class predicts movie ratings using a fine-tuned BERT model, using title,summary and genres as inputs\n",
    "\n",
    "    # initialize the model and tokenizer\n",
    "    def __init__(self, model_path, tokenizer_path):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        \n",
    "    def __preProcessInput(self, titles, summaries, genres):\n",
    "    # titles: list of strings in the form: [title_1, title_2, ...]\n",
    "    # summaries: list of summaries(strings) in the form: [summary_1, summary_2, ...]\n",
    "    # genres: list of genres in the form: [[genres_1], [genres_2], ...] with genres_i = \"genres_i1\", \"genres_i2\", ...\n",
    "    \n",
    "        inputs = []\n",
    "    \n",
    "        for i in range(len(titles)):\n",
    "        # normalice spacing in the titles\n",
    "            title_i = (' ').join(titles[i].split())\n",
    "        \n",
    "        # normalice spacing in the summaries\n",
    "            summary_i = (' ').join(summaries[i].split())\n",
    "        \n",
    "            if genres[i] == []:\n",
    "                genres_i = 'NonGiven'\n",
    "            else:\n",
    "            # convert the lists of genres to strings separated by '|'\n",
    "                genres_i = '|'.join(genres[i])\n",
    "            \n",
    "            input_i = {'title': title_i, 'summary': summary_i, 'genres': genres_i}\n",
    "            inputs.append(input_i)\n",
    "        \n",
    "        return inputs\n",
    "        \n",
    "        \n",
    "    def predict(self, title, summary, genre):\n",
    "        movies = self.__preProcessInput(title, summary, genre)\n",
    "        \n",
    "        return movies\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "# cls = MovieClassifier(blah, blarg)\n",
    "\n",
    "# pred = cls.predict\n",
    "\n",
    "# MovieClassifier().predict(cls, title, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "937adac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__preProcessInput() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m MovieClassifier(model_path, tokenizer_path)\n\u001b[0;32m----> 2\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthis  is a Title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthis movie is about icecream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRomance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pred\n",
      "Cell \u001b[0;32mIn[19], line 98\u001b[0m, in \u001b[0;36mMovieClassifier.predict\u001b[0;34m(self, title, summary, genre)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, title, summary, genre):\n\u001b[0;32m---> 98\u001b[0m     movies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__preProcessInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m movies\n",
      "\u001b[0;31mTypeError\u001b[0m: __preProcessInput() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "cls = MovieClassifier(model_path, tokenizer_path)\n",
    "pred = cls.predict([\"this  is a Title\"], [\"this movie is about icecream\"], [[\"Romance\"]])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc5d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = preProcessInput([\"this is the    first title\", \"here is another title\"], \n",
    "                [\"the first movie   is about icecream\", \"the second movie is about forests\"], \n",
    "                [[\"Action\", \"Fiction\"], [\"Romance\", \"Thriller\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91364035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'this is the first title',\n",
       "  'summary': 'the first movie is about icecream',\n",
       "  'genres': 'Action|Fiction'},\n",
       " {'title': 'here is another title',\n",
       "  'summary': 'the second movie is about forests',\n",
       "  'genres': 'Romance|Thriller'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fa7d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action|Fiction', 'Romance|Thriller']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['genres'] for m in movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba516c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1142, 1110,  ...,    0,    0,    0],\n",
       "        [ 101, 1303, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizeInputs(movies)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "180b370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_input.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cebce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.9529,  5.2467, -2.4924],\n",
       "        [-2.3565,  3.7838, -1.5596]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "639bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "    \n",
    "#     a = model(**tokenized_input)\n",
    "#     a\n",
    "    \n",
    "# logits = a.logits\n",
    "# logits\n",
    "\n",
    "# predictions = np.argmax(logits, axis = -1)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cece7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(predictions)):\n",
    "#     print(predictions[i] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc4c5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelPredictions(model, tokenized_input)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "876668a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(1), 'average'), (tensor(1), 'average')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMovieRating(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127a96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a2b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e1825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1b585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcffd5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
