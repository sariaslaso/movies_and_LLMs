{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbf794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4207818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained('model/fine_tuned_BERT')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")\n",
    "\n",
    "model_path = 'model/fine_tuned_BERT'\n",
    "tokenizer_path = 'tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ca0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def preProcessInput(titles, summaries, genres):\n",
    "# titles: list of strings in the form: [title_1, title_2, ...]\n",
    "# summaries: list of summaries(strings) in the form: [summary_1, summary_2, ...]\n",
    "# genres: list of genres in the form: [[genres_1], [genres_2], ...] with genres_i = \"genres_i1\", \"genres_i2\", ...\n",
    "    \n",
    "    inputs = []\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        # normalice spacing in the titles\n",
    "        title_i = (' ').join(titles[i].split())\n",
    "        \n",
    "        # normalice spacing in the summaries\n",
    "        summary_i = (' ').join(summaries[i].split())\n",
    "        \n",
    "        if genres[i] == []:\n",
    "            genres_i = 'NonGiven'\n",
    "        else:\n",
    "            # convert the lists of genres to strings separated by '|'\n",
    "            genres_i = '|'.join(genres[i])\n",
    "            \n",
    "        input_i = {'title': title_i, 'summary': summary_i, 'genres': genres_i}\n",
    "        inputs.append(input_i)\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "\n",
    "def tokenizeInputs(inputs):\n",
    "    title_mod = [movie['title'] + '<SEP>' + movie['summary'] for movie in inputs]\n",
    "    genres_list = [movie['genres'] for movie in inputs]\n",
    "    \n",
    "        \n",
    "    return tokenizer(title_mod, genres_list, padding = 'max_length', truncation = True, \n",
    "                     return_tensors = \"pt\")\n",
    "\n",
    "\n",
    "def modelPredictions(model, tokenized_input):\n",
    "# generate model predictions using the model logits and tokenized input and determine \n",
    "# the most likely rating using\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(**tokenized_input)\n",
    "        \n",
    "    logits = model_output.logits\n",
    "    predictions = np.argmax(logits, axis = -1)\n",
    "    \n",
    "    return predictions           \n",
    "            \n",
    "def predMovieRating(predictions):\n",
    "    predicted_ratings = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        if pred == 0:\n",
    "            predicted_ratings.append((pred, \"bad\"))\n",
    "        elif pred == 1:\n",
    "            predicted_ratings.append((pred, \"average\"))\n",
    "        else:\n",
    "            predicted_ratings.append((pred, \"good\"))\n",
    "            \n",
    "    return predicted_ratings\n",
    "            \n",
    "\n",
    "class MovieClassifier:\n",
    "#     this class predicts movie ratings using a fine-tuned BERT model, using title,summary and genres as inputs\n",
    "    ratings = ['bad', 'average', 'good']\n",
    "\n",
    "    # initialize the model and tokenizer\n",
    "    def __init__(self, model_path, tokenizer_path):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        \n",
    "    def __preProcessInput(self, titles, summaries, genres):\n",
    "    # titles: list of strings in the form: [title_1, title_2, ...]\n",
    "    # summaries: list of summaries(strings) in the form: [summary_1, summary_2, ...]\n",
    "    # genres: list of genres in the form: [[genres_1], [genres_2], ...] with genres_i = \"genres_i1\", \"genres_i2\", ...\n",
    "    \n",
    "        inputs = []\n",
    "    \n",
    "        for i in range(len(titles)):\n",
    "        # normalice spacing in the titles\n",
    "            title_i = (' ').join(titles[i].split())\n",
    "        \n",
    "        # normalice spacing in the summaries\n",
    "            summary_i = (' ').join(summaries[i].split())\n",
    "        \n",
    "            if genres[i] == []:\n",
    "                genres_i = 'NonGiven'\n",
    "            else:\n",
    "            # convert the lists of genres to strings separated by '|'\n",
    "                genres_i = '|'.join(genres[i])\n",
    "            \n",
    "            input_i = {'title': title_i, 'summary': summary_i, 'genres': genres_i}\n",
    "            inputs.append(input_i)\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "    def __tokenizeInputs(self, inputs):\n",
    "        title_mod = [movie['title'] + '<SEP>' + movie['summary'] for movie in inputs]\n",
    "        genres_list = [movie['genres'] for movie in inputs]\n",
    "        \n",
    "        return self.tokenizer(title_mod, genres_list, padding = 'max_length', \n",
    "                         truncation = True, \n",
    "                         return_tensors = \"pt\")\n",
    "    \n",
    "    def __modelPredictions(self, model, tokenized_input):\n",
    "    # generate model predictions using the model logits and tokenized input and determine \n",
    "    # the most likely rating using\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**tokenized_input)\n",
    "        \n",
    "        logits = model_output.logits\n",
    "        predictions = np.argmax(logits, axis = -1)\n",
    "    \n",
    "        return predictions\n",
    "    \n",
    "    def __predMovieRating(self, predictions):\n",
    "        predicted_ratings = []\n",
    "    \n",
    "        for pred in predictions:\n",
    "            predicted_ratings.append((pred, self.ratings[pred]))\n",
    "            \n",
    "        return predicted_ratings\n",
    "    \n",
    "    def predict(self, title, summary, genre):\n",
    "        movies = self.__preProcessInput(title, summary, genre)\n",
    "        tokenized_movies = self.__tokenizeInputs(movies)\n",
    "        predictions = self.__modelPredictions(self.model, tokenized_movies)\n",
    "        pred_ratings = self.__predMovieRating(predictions)\n",
    "        \n",
    "        return pred_ratings\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "# cls = MovieClassifier(blah, blarg)\n",
    "\n",
    "# pred = cls.predict\n",
    "\n",
    "# MovieClassifier().predict(cls, title, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fe30c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(1), 'average'), (tensor(1), 'average')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = MovieClassifier(model_path, tokenizer_path)\n",
    "pred = cls.predict(['this is the title', 'second movie'], [\"this movie is about icecream\", 'second summary'], [['Romance'], []])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f78c2f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['average', 'average']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rating[1] for rating in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d50bc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'average'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc5d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = preProcessInput([\"this is the    first title\", \"here is another title\"], \n",
    "                [\"the first movie   is about icecream\", \"the second movie is about forests\"], \n",
    "                [[\"Action\", \"Fiction\"], [\"Romance\", \"Thriller\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91364035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'this is the first title',\n",
       "  'summary': 'the first movie is about icecream',\n",
       "  'genres': 'Action|Fiction'},\n",
       " {'title': 'here is another title',\n",
       "  'summary': 'the second movie is about forests',\n",
       "  'genres': 'Romance|Thriller'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fa7d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action|Fiction', 'Romance|Thriller']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['genres'] for m in movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba516c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1142, 1110,  ...,    0,    0,    0],\n",
       "        [ 101, 1303, 1110,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizeInputs(movies)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "180b370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_input.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cebce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.9529,  5.2467, -2.4924],\n",
       "        [-2.3565,  3.7838, -1.5596]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "639bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "    \n",
    "#     a = model(**tokenized_input)\n",
    "#     a\n",
    "    \n",
    "# logits = a.logits\n",
    "# logits\n",
    "\n",
    "# predictions = np.argmax(logits, axis = -1)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cece7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(predictions)):\n",
    "#     print(predictions[i] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc4c5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelPredictions(model, tokenized_input)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "876668a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(1), 'average'), (tensor(1), 'average')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMovieRating(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127a96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a2b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e1825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1b585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcffd5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
