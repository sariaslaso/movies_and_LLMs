{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_dataset\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec393e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def tokenizerFunction(example):\n",
    "    \n",
    "    title_mod = [f\"{t}[SEP]{s}\" for t, s in zip(example['title'], example['summary'])]\n",
    "    \n",
    "    return tokenizer(title_mod, example['genres'], padding = 'max_length', truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68934d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets using hugging face\n",
    "\n",
    "data_files = {\n",
    "        'train' : '../datasets/training',\n",
    "        'val' : '../datasets/validation',\n",
    "        'test' : '../datasets/test',\n",
    "        } \n",
    "\n",
    "training = load_dataset('json', data_files = data_files, split = 'train')\n",
    "validation = load_dataset('json', data_files = data_files, split = 'val')\n",
    "test = load_dataset('json', data_files = data_files, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using PyTorch Trainer API\n",
    "\n",
    "# tokenize datasets using DeBERTaV3 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "tokenized_training = training.map(tokenizerFunction, batched = True)\n",
    "tokenized_validation = validation.map(tokenizerFunction, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and\n",
    "# evaluation\n",
    "# the model will be saved in the input directory\n",
    "\n",
    "training_args = TrainingArguments(output_dir = \"test_trainer\", evaluation_strategy = \"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ea727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_metrics() function to calculate a metric when evaluating the model during training \n",
    "# (otherwise the evaluation would just print the loss, which is not a very intuitive number).\n",
    "\n",
    "\n",
    "def computeMetrics(eval_pred):\n",
    "#     convert the logits to predictions before passing the predictions to compute\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis = -1)\n",
    "        \n",
    "    accuracy = accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    precision = precision_score(y_true = labels, y_pred = predictions, average = 'macro')\n",
    "    recall = recall_score(y_true = labels, y_pred = predictions, average = 'macro')\n",
    "    f1 = f1_score(y_true = labels, y_pred = predictions, average = 'macro')\n",
    "    classification_report = classification_report(labels, np.argmax(predictions, axis = -1), \n",
    "                                                  output_dict = True, labels = [0, 1, 2], \n",
    "                                                  target_names = ['bad_rating', 'average_rating', 'good_rating'])\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy, \n",
    "        'balanced_accuracy': balanced_accuracy, \n",
    "        'precision': precision, \n",
    "        'recall': recall, \n",
    "        'f1': f1, \n",
    "        'classification_report': classification_report,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER\n",
    "# define the trainer object\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_training,\n",
    "    eval_dataset = tokenized_validation,\n",
    "    compute_metrics = computeMetrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787926fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir = 'model/fine_tuned_DeBERTaV3')\n",
    "tokenizer.save_pretrained('model/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8532053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666edecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
