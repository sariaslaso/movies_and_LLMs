{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f5c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_dataset\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "from focal_trainer import FocalLossTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec393e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def tokenizerFunction(example):\n",
    "    \n",
    "    title_mod = [f\"{t}[SEP]{s}\" for t, s in zip(example['title'], example['summary'])]\n",
    "    \n",
    "    return tokenizer(title_mod, example['genres'], padding = 'max_length', truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68934d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets using hugging face\n",
    "\n",
    "data_files = {\n",
    "        'train' : '../data/training',\n",
    "        'val' : '../data/validation',\n",
    "        'test' : '../data/test',\n",
    "        } \n",
    "\n",
    "training = load_dataset('json', data_files = data_files, split = 'train')\n",
    "validation = load_dataset('json', data_files = data_files, split = 'val')\n",
    "test = load_dataset('json', data_files = data_files, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b146c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train using PyTorch Trainer API\n",
    "\n",
    "# tokenize datasets using DeBERTaV3 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'microsoft/deberta-v3-base',\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    max_length = 512,\n",
    "    model_max_length = 512,\n",
    ")\n",
    "\n",
    "tokenized_training = training.map(tokenizerFunction, batched = True).remove_columns([\"genres\", \"title\", \"summary\",])\n",
    "tokenized_validation = validation.map(tokenizerFunction, batched = True).remove_columns([\"genres\", \"title\", \"summary\",])\n",
    "tokenized_test = test.map(tokenizerFunction, batched = True).remove_columns([\"genres\", \"title\", \"summary\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efa736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a8df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and\n",
    "# evaluation\n",
    "# the model will be saved in the input directory\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 24,\n",
    "    gradient_accumulation_steps = 2,\n",
    "    per_device_eval_batch_size = 128,\n",
    "    num_train_epochs = 15,\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    output_dir = '../models/fine_tuned_DeBERTaV3',\n",
    "    log_level = \"info\",\n",
    "    fp16 = True,\n",
    "    optim = \"adamw_torch\",\n",
    "    learning_rate = 5.0E-6,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_balanced_accuracy\",\n",
    "    greater_is_better = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f8ea727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_metrics() function to calculate a metric when evaluating the model during training \n",
    "# (otherwise the evaluation would just print the loss, which is not a very intuitive number).\n",
    "\n",
    "\n",
    "def computeMetrics(eval_pred):\n",
    "#     convert the logits to predictions before passing the predictions to compute\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis = -1)\n",
    "        \n",
    "    accuracy = accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true = labels, y_pred = predictions)\n",
    "    precision = precision_score(y_true = labels, y_pred = predictions, average = 'macro')\n",
    "    recall = recall_score(y_true = labels, y_pred = predictions, average = 'macro')\n",
    "    f1 = f1_score(y_true = labels, y_pred = predictions, average = 'macro')\n",
    "    cls_report = classification_report(labels, predictions, \n",
    "                                                  output_dict = True, labels = [0, 1, 2], \n",
    "                                                  target_names = ['bad_rating', 'average_rating', 'good_rating'])\n",
    "\n",
    "    res = {\n",
    "        'accuracy': accuracy, \n",
    "        'balanced_accuracy': balanced_accuracy, \n",
    "        'precision': precision, \n",
    "        'recall': recall, \n",
    "        'f1': f1, \n",
    "        'classification_report': cls_report,\n",
    "        }\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18a6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "# TRAINER\n",
    "# define the trainer object\n",
    "\n",
    "#trainer = Trainer(\n",
    "trainer = FocalLossTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_training,\n",
    "    eval_dataset = tokenized_validation,\n",
    "    compute_metrics = computeMetrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9a6634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 370,940\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 24\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 115,920\n",
      "  Number of trainable parameters = 184,424,451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61824' max='115920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 61824/115920 12:15:35 < 10:43:40, 1.40 it/s, Epoch 8/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.099282</td>\n",
       "      <td>0.726757</td>\n",
       "      <td>0.395734</td>\n",
       "      <td>0.591128</td>\n",
       "      <td>0.395734</td>\n",
       "      <td>0.397759</td>\n",
       "      <td>{'bad_rating': {'precision': 0.4973544973544973, 'recall': 0.06483503851017358, 'f1-score': 0.11471575307637547, 'support': 8699.0}, 'average_rating': {'precision': 0.7393844620487, 'recall': 0.9675076452599388, 'f1-score': 0.8382019188623192, 'support': 44472.0}, 'good_rating': {'precision': 0.5366439727673208, 'recall': 0.15485958627065757, 'f1-score': 0.24035874439461882, 'support': 8653.0}, 'accuracy': 0.726756599378882, 'macro avg': {'precision': 0.5911276440568393, 'recall': 0.39573409001359, 'f1-score': 0.39775880544443787, 'support': 61824.0}, 'weighted avg': {'precision': 0.6769534948413591, 'recall': 0.726756599378882, 'f1-score': 0.6527279420112428, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.100606</td>\n",
       "      <td>0.728503</td>\n",
       "      <td>0.400215</td>\n",
       "      <td>0.601941</td>\n",
       "      <td>0.400215</td>\n",
       "      <td>0.407127</td>\n",
       "      <td>{'bad_rating': {'precision': 0.48288075560802834, 'recall': 0.09403379698815956, 'f1-score': 0.15741364379871067, 'support': 8699.0}, 'average_rating': {'precision': 0.7408970340004822, 'recall': 0.9672378125562151, 'f1-score': 0.8390714912708476, 'support': 44472.0}, 'good_rating': {'precision': 0.582046332046332, 'recall': 0.13937362764359182, 'f1-score': 0.2248951048951049, 'support': 8653.0}, 'accuracy': 0.7285034937888198, 'macro avg': {'precision': 0.6019413738849476, 'recall': 0.40021507906265547, 'f1-score': 0.40712674665488774, 'support': 61824.0}, 'weighted avg': {'precision': 0.6823595933666633, 'recall': 0.7285034937888198, 'f1-score': 0.657196978355646, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.103557</td>\n",
       "      <td>0.724136</td>\n",
       "      <td>0.420492</td>\n",
       "      <td>0.567201</td>\n",
       "      <td>0.420492</td>\n",
       "      <td>0.435467</td>\n",
       "      <td>{'bad_rating': {'precision': 0.45172878311629994, 'recall': 0.11564547649155076, 'f1-score': 0.18414790408200624, 'support': 8699.0}, 'average_rating': {'precision': 0.7487216946676406, 'recall': 0.9449766144990106, 'f1-score': 0.8354787725768134, 'support': 44472.0}, 'good_rating': {'precision': 0.5011534025374856, 'recall': 0.2008551947301514, 'f1-score': 0.28677501856282483, 'support': 8653.0}, 'accuracy': 0.7241362577639752, 'macro avg': {'precision': 0.5672012934404753, 'recall': 0.4204924285735709, 'f1-score': 0.43546723174054813, 'support': 61824.0}, 'weighted avg': {'precision': 0.6722829367518257, 'recall': 0.7241362577639752, 'f1-score': 0.6670351130187231, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.116994</td>\n",
       "      <td>0.715984</td>\n",
       "      <td>0.429990</td>\n",
       "      <td>0.539995</td>\n",
       "      <td>0.429990</td>\n",
       "      <td>0.446655</td>\n",
       "      <td>{'bad_rating': {'precision': 0.4074074074074074, 'recall': 0.1353029083802736, 'f1-score': 0.2031411805315844, 'support': 8699.0}, 'average_rating': {'precision': 0.7526696583936258, 'recall': 0.9239971217844937, 'f1-score': 0.8295799812248277, 'support': 44472.0}, 'good_rating': {'precision': 0.4599078341013825, 'recall': 0.23067144343002427, 'f1-score': 0.3072423612714539, 'support': 8653.0}, 'accuracy': 0.7159840838509317, 'macro avg': {'precision': 0.5399949666341385, 'recall': 0.4299904911982639, 'f1-score': 0.4466545076759553, 'support': 61824.0}, 'weighted avg': {'precision': 0.6631137515139367, 'recall': 0.7159840838509317, 'f1-score': 0.6683290341381452, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.125013</td>\n",
       "      <td>0.685883</td>\n",
       "      <td>0.459687</td>\n",
       "      <td>0.502182</td>\n",
       "      <td>0.459687</td>\n",
       "      <td>0.474179</td>\n",
       "      <td>{'bad_rating': {'precision': 0.3218321530812114, 'recall': 0.24554546499597654, 'f1-score': 0.27856025039123633, 'support': 8699.0}, 'average_rating': {'precision': 0.7666950492640798, 'recall': 0.8503777657852132, 'f1-score': 0.8063711379773556, 'support': 44472.0}, 'good_rating': {'precision': 0.4180174031735199, 'recall': 0.2831387957933665, 'f1-score': 0.33760507096596387, 'support': 8653.0}, 'accuracy': 0.6858825051759835, 'macro avg': {'precision': 0.502181535172937, 'recall': 0.4596873421915187, 'f1-score': 0.4741788197781853, 'support': 61824.0}, 'weighted avg': {'precision': 0.6552986658932791, 'recall': 0.6858825051759835, 'f1-score': 0.6664956901098411, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.149842</td>\n",
       "      <td>0.700763</td>\n",
       "      <td>0.432632</td>\n",
       "      <td>0.507462</td>\n",
       "      <td>0.432632</td>\n",
       "      <td>0.448325</td>\n",
       "      <td>{'bad_rating': {'precision': 0.3568716780561883, 'recall': 0.16208759627543395, 'f1-score': 0.22292490118577074, 'support': 8699.0}, 'average_rating': {'precision': 0.7541458427987279, 'recall': 0.8957771181867242, 'f1-score': 0.8188825851011347, 'support': 44472.0}, 'good_rating': {'precision': 0.41136858783917607, 'recall': 0.24003235871951925, 'f1-score': 0.3031674208144796, 'support': 8653.0}, 'accuracy': 0.7007634575569358, 'macro avg': {'precision': 0.5074620362313641, 'recall': 0.4326323577272258, 'f1-score': 0.448324969033795, 'support': 61824.0}, 'weighted avg': {'precision': 0.650271303036494, 'recall': 0.7007634575569358, 'f1-score': 0.6628474012089217, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.679267</td>\n",
       "      <td>0.457234</td>\n",
       "      <td>0.489766</td>\n",
       "      <td>0.457234</td>\n",
       "      <td>0.468459</td>\n",
       "      <td>{'bad_rating': {'precision': 0.3165735567970205, 'recall': 0.2149672376135188, 'f1-score': 0.2560591537724223, 'support': 8699.0}, 'average_rating': {'precision': 0.7652524508299052, 'recall': 0.8407762187443785, 'f1-score': 0.8012385758520566, 'support': 44472.0}, 'good_rating': {'precision': 0.3874716553287982, 'recall': 0.3159597827343118, 'f1-score': 0.34808071805971097, 'support': 8653.0}, 'accuracy': 0.6792669513457557, 'macro avg': {'precision': 0.489765887651908, 'recall': 0.4572344130307364, 'f1-score': 0.4684594825613966, 'support': 61824.0}, 'weighted avg': {'precision': 0.6492458041770982, 'recall': 0.6792669513457557, 'f1-score': 0.6611038266260618, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.176479</td>\n",
       "      <td>0.674544</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.481574</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.461690</td>\n",
       "      <td>{'bad_rating': {'precision': 0.31450026819238336, 'recall': 0.20220715024715485, 'f1-score': 0.2461516932549678, 'support': 8699.0}, 'average_rating': {'precision': 0.7632054176072235, 'recall': 0.8362790070156503, 'f1-score': 0.7980730027252634, 'support': 44472.0}, 'good_rating': {'precision': 0.3670177309692041, 'recall': 0.3181555529874032, 'f1-score': 0.34084437291073416, 'support': 8653.0}, 'accuracy': 0.6745438664596274, 'macro avg': {'precision': 0.48157447225627026, 'recall': 0.4522139034167361, 'f1-score': 0.4616896896303218, 'support': 61824.0}, 'weighted avg': {'precision': 0.6446188145527709, 'recall': 0.6745438664596274, 'f1-score': 0.6564198776465363, 'support': 61824.0}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-7728\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-7728/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-7728/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-15456\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-15456/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-15456/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-23184\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-23184/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-23184/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-30912\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-30912/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-30912/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-38640\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-38640/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-38640/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-46368\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-46368/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-46368/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-54096\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-54096/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-54096/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3/checkpoint-61824\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/checkpoint-61824/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/checkpoint-61824/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../models/fine_tuned_DeBERTaV3/checkpoint-38640 (score: 0.4596873421915187).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=61824, training_loss=0.07559675356184227, metrics={'train_runtime': 44136.8539, 'train_samples_per_second': 126.065, 'train_steps_per_second': 2.626, 'total_flos': 7.808083318923264e+17, 'train_loss': 0.07559675356184227, 'epoch': 8.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac218aa5-647a-43a7-8417-66b111dea154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='966' max='483' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [483/483 09:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_balanced_accuracy so early stopping is disabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.12501265108585358,\n",
       " 'val_accuracy': 0.6858825051759835,\n",
       " 'val_balanced_accuracy': 0.4596873421915187,\n",
       " 'val_precision': 0.502181535172937,\n",
       " 'val_recall': 0.4596873421915187,\n",
       " 'val_f1': 0.4741788197781853,\n",
       " 'val_classification_report': {'bad_rating': {'precision': 0.3218321530812114,\n",
       "   'recall': 0.24554546499597654,\n",
       "   'f1-score': 0.27856025039123633,\n",
       "   'support': 8699.0},\n",
       "  'average_rating': {'precision': 0.7666950492640798,\n",
       "   'recall': 0.8503777657852132,\n",
       "   'f1-score': 0.8063711379773556,\n",
       "   'support': 44472.0},\n",
       "  'good_rating': {'precision': 0.4180174031735199,\n",
       "   'recall': 0.2831387957933665,\n",
       "   'f1-score': 0.33760507096596387,\n",
       "   'support': 8653.0},\n",
       "  'accuracy': 0.6858825051759835,\n",
       "  'macro avg': {'precision': 0.502181535172937,\n",
       "   'recall': 0.4596873421915187,\n",
       "   'f1-score': 0.4741788197781853,\n",
       "   'support': 61824.0},\n",
       "  'weighted avg': {'precision': 0.6552986658932791,\n",
       "   'recall': 0.6858825051759835,\n",
       "   'f1-score': 0.6664956901098411,\n",
       "   'support': 61824.0}},\n",
       " 'val_runtime': 279.6301,\n",
       " 'val_samples_per_second': 221.092,\n",
       " 'val_steps_per_second': 1.727,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_validation, metric_key_prefix = \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb496579-ae77-45b2-ba4e-6bf4c33938da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61824\n",
      "  Batch size = 128\n",
      "early stopping required metric_for_best_model, but did not find eval_balanced_accuracy so early stopping is disabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.1266673505306244,\n",
       " 'test_accuracy': 0.6852840320910973,\n",
       " 'test_balanced_accuracy': 0.4550989336998814,\n",
       " 'test_precision': 0.5002329412741152,\n",
       " 'test_recall': 0.4550989336998814,\n",
       " 'test_f1': 0.46988696029032245,\n",
       " 'test_classification_report': {'bad_rating': {'precision': 0.3149879372738239,\n",
       "   'recall': 0.23874285714285715,\n",
       "   'f1-score': 0.27161617474970745,\n",
       "   'support': 8750.0},\n",
       "  'average_rating': {'precision': 0.7646394579770931,\n",
       "   'recall': 0.8530357906103075,\n",
       "   'f1-score': 0.8064224573342549,\n",
       "   'support': 44453.0},\n",
       "  'good_rating': {'precision': 0.4210714285714286,\n",
       "   'recall': 0.27351815334647955,\n",
       "   'f1-score': 0.33162224878700514,\n",
       "   'support': 8621.0},\n",
       "  'accuracy': 0.6852840320910973,\n",
       "  'macro avg': {'precision': 0.5002329412741152,\n",
       "   'recall': 0.4550989336998814,\n",
       "   'f1-score': 0.46988696029032245,\n",
       "   'support': 61824.0},\n",
       "  'weighted avg': {'precision': 0.6530913409406697,\n",
       "   'recall': 0.6852840320910973,\n",
       "   'f1-score': 0.664522748960474,\n",
       "   'support': 61824.0}},\n",
       " 'test_runtime': 279.6668,\n",
       " 'test_samples_per_second': 221.063,\n",
       " 'test_steps_per_second': 1.727,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_test, metric_key_prefix = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "787926fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../models/fine_tuned_DeBERTaV3\n",
      "Configuration saved in ../models/fine_tuned_DeBERTaV3/config.json\n",
      "Model weights saved in ../models/fine_tuned_DeBERTaV3/model.safetensors\n",
      "tokenizer config file saved in ../models/fine_tuned_DeBERTaV3/tokenizer_config.json\n",
      "Special tokens file saved in ../models/fine_tuned_DeBERTaV3/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/fine_tuned_DeBERTaV3/tokenizer_config.json',\n",
       " '../models/fine_tuned_DeBERTaV3/special_tokens_map.json',\n",
       " '../models/fine_tuned_DeBERTaV3/spm.model',\n",
       " '../models/fine_tuned_DeBERTaV3/added_tokens.json',\n",
       " '../models/fine_tuned_DeBERTaV3/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(output_dir = '../models/fine_tuned_DeBERTaV3')\n",
    "tokenizer.save_pretrained('../models/fine_tuned_DeBERTaV3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8532053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.139  0.719   0.142'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 8750.0 + 8621.0 + 44453.0\n",
    "good = 8621.0\n",
    "average = 44453.0\n",
    "bad = 8750.0\n",
    "\n",
    "f\"{good/total:1.3F}  {average/total:1.3F}   {bad/total:1.3F}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1a3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
